\documentclass{beamer}

% Beamer style
%\usetheme[secheader]{Madrid}
\usetheme{CambridgeUS}
\usecolortheme[rgb={0.65,0.15,0.25}]{structure}
%\usefonttheme[onlymath]{serif}
\beamertemplatenavigationsymbolsempty
%\AtBeginSubsection

% Packages
%\usepackage[french]{babel}
\usepackage[latin1]{inputenc}
\usepackage{color}
%\usepackage{dsfont, stmaryrd}
\usepackage{amsmath, amsfonts, amssymb}
\usepackage{epsfig}
\usepackage{url}
\usepackage{/home/robin/LATEX/astats}
%\usepackage[all]{xy}
\usepackage{graphicx}

% Commands
\definecolor{darkred}{rgb}{0.65,0.15,0.25}
%\newcommand{\emphase}[1]{\textcolor{darkred}{#1}}
\newcommand{\emphase}[1]{{#1}}
\newcommand{\paragraph}[1]{\textcolor{darkred}{#1}}
\newcommand{\refer}[1]{[{\footnotesize{\textcolor{blue}{{\cite{#1}}}}]}}
\newcommand{\Refer}[1]{[{\footnotesize{\textcolor{blue}{{\sl #1}}]}}}
\newcommand{\newblock}{}

% Symbols
\newcommand{\Abf}{{\bf A}}
\newcommand{\Beta}{\text{B}}
\newcommand{\Bcal}{\mathcal{B}}
\newcommand{\BIC}{\text{BIC}}
\newcommand{\Ccal}{\mathcal{C}}
\newcommand{\dd}{\text{~d}}
\newcommand{\dbf}{{\bf d}}
\newcommand{\Dcal}{\mathcal{D}}
\newcommand{\Esp}{\mathbb{E}}
\newcommand{\Ebf}{{\bf E}}
\newcommand{\Ecal}{\mathcal{E}}
\newcommand{\Gcal}{\mathcal{G}}
\newcommand{\Gam}{\mathcal{G}\text{am}}
\newcommand{\Ibb}{\mathbb{I}}
\newcommand{\Ibf}{{\bf I}}
\newcommand{\ICL}{\text{ICL}}
\newcommand{\Cov}{\mathbb{C}\text{ov}}
\newcommand{\Corr}{\mathbb{C}\text{orr}}
\newcommand{\Var}{\mathbb{V}}
\newcommand{\Vsf}{\mathsf{V}}
\newcommand{\pen}{\text{pen}}
\newcommand{\Fcal}{\mathcal{F}}
\newcommand{\Hbf}{{\bf H}}
\newcommand{\Hcal}{\mathcal{H}}
\newcommand{\Jcal}{\mathcal{J}}
\newcommand{\Kbf}{{\bf K}}
\newcommand{\Lcal}{\mathcal{L}}
\newcommand{\Mcal}{\mathcal{M}}
\newcommand{\mbf}{{\bf m}}
\newcommand{\mum}{\mu(\mbf)}
\newcommand{\Ncal}{\mathcal{N}}
\newcommand{\Nbf}{{\bf N}}
\newcommand{\Nm}{N(\mbf)}
\newcommand{\Ocal}{\mathcal{O}}
\newcommand{\Obf}{{\bf 0}}
\newcommand{\Omegas}{\underset{s}{\Omega}}
\newcommand{\Pbf}{{\bf P}}
\newcommand{\Pcal}{\mathcal{P}}
\newcommand{\Qcal}{\mathcal{Q}}
\newcommand{\Rbb}{\mathbb{R}}
\newcommand{\Rcal}{\mathcal{R}}
\newcommand{\sbf}{{\bf s}}
\newcommand{\Sbf}{{\bf S}}
\newcommand{\Scal}{\mathcal{S}}
\newcommand{\Ucal}{\mathcal{U}}
\newcommand{\Vcal}{\mathcal{V}}
\newcommand{\Tbf}{{\bf T}}
\newcommand{\ubf}{{u}}
\newcommand{\Ubf}{{U}}
\newcommand{\Wbf}{{W}}
\newcommand{\xbf}{{x}}
\newcommand{\Xbf}{{X}}
\newcommand{\ybf}{{y}}
\newcommand{\Ybf}{{Y}}
\newcommand{\zbf}{{z}}
\newcommand{\Zbf}{{Z}}
\newcommand{\betabf}{\text{\mathversion{bold}{$\beta$}}}
\newcommand{\pibf}{\text{\mathversion{bold}{$\pi$}}}
\newcommand{\phibf}{\text{\mathversion{bold}{$\phi$}}}
\newcommand{\Sigmabf}{\text{\mathversion{bold}{$\Sigma$}}}
\newcommand{\gammabf}{\text{\mathversion{bold}{$\gamma$}}}
\newcommand{\mubf}{\text{\mathversion{bold}{$\mu$}}}
\newcommand{\nubf}{\text{\mathversion{bold}{$\nu$}}}
\newcommand{\Thetabf}{{\Theta}}
\newcommand{\thetabf}{{\theta}}
\newcommand{\BP}{\text{BP}}
\newcommand{\EM}{\text{EM}}
\newcommand{\VEM}{\text{VEM}}
\newcommand{\VBEM}{\text{VBEM}}
\newcommand{\cst}{\text{cst}}
\newcommand{\obs}{\text{obs}}
\newcommand{\ra}{\emphase{\mathversion{bold}{$\rightarrow$}~}}
\newcommand{\QZ}{Q_{\Zbf}}
\newcommand{\Qt}{Q_{\thetabf}}
%\newcommand{\transp}{\text{{\tiny $\top$}}}
\newcommand{\transp}{\text{{\tiny \mathversion{bold}{$\top$}}}}

% Directory
\newcommand{\figmixt}{/home/robin/ENSEIGN/COURS/MELANGE}
\newcommand{\figbma}{/home/robin/RECHERCHE/RUPTURES/MELANGE/Exemples/Grippe}
\newcommand{\fignet}{../FIGURES}
\newcommand{\figeco}{/home/robin/RECHERCHE/ECOLOGIE/EXPOSES/FIGURES}
%\newcommand{\figmotif}{/home/robin/RECHERCHE/RESEAUX/Motifs/FIGURES}


%--------------------------------------------------------------------
%--------------------------------------------------------------------

%--------------------------------------------------------------------
%--------------------------------------------------------------------
\begin{document}
%--------------------------------------------------------------------
%--------------------------------------------------------------------

%--------------------------------------------------------------------
\title[Heterogeneity in interaction networks]{Deciphering and modeling heterogeneity in
interaction networks}   

\author{S. Robin}

\institute[INRA / AgroParisTech]{INRA / AgroParisTech \\
  \vspace{-1cm}
  \begin{tabular}{ccccc}
    \includegraphics[width=2.5cm]{\fignet/LogoINRA-Couleur} & 
    \hspace{.5cm} &
    \includegraphics[width=3.75cm]{\fignet/logagroptechsolo} & 
    \hspace{.5cm} &
    \includegraphics[width=2.5cm]{\fignet/logo-ssb}
    \\ 
  \end{tabular} \\
  \bigskip
  }

\date[CLADAG'13]{CLADAG meeting, September 2013, Modena}

%--------------------------------------------------------------------
%--------------------------------------------------------------------
\maketitle
%--------------------------------------------------------------------

%--------------------------------------------------------------------
\frame{\frametitle{Outline}
  \tableofcontents
  }
%--------------------------------------------------------------------

%--------------------------------------------------------------------
%--------------------------------------------------------------------
\section{Heterogeneity in interaction networks}
\frame{\frametitle{Heterogeneity in interaction networks}}
%--------------------------------------------------------------------

%--------------------------------------------------------------------
\frame{\frametitle{Understanding network structure}

  Networks describe interactions between entities. \\
  ~\\
  Observed networks display heterogeneous topologies, that one would like to decipher and better understand. \\
  ~\\

  \pause
    \begin{tabular}{ll}
    %\hspace{-.5cm}
    \begin{tabular}{p{.5\textwidth}}
      \paragraph{Dolphine social network.} \\
      %\epsfig{file=../Figures/NeG04-Fig11.ps, clip=, width=.5\textwidth}
      \includegraphics[width=.4\textwidth]{../FIGURES/NeG04-Fig11} \\
      \refer{NeG04}
    \end{tabular}
    & 
    \hspace{-.5cm}
    \begin{tabular}{p{.5\textwidth}}
      \paragraph{Hyperlink network.} \\
      \includegraphics[width=.4\textwidth]{../FIGURES/NeG04-Fig13} 
    \end{tabular} 
  \end{tabular} 
  }

%--------------------------------------------------------------------
\frame{\frametitle{Modeling network heterogeneity}

  \paragraph{Latent variable models} allow to capture
  the underlying structure of a network.

  \bigskip \bigskip \pause
  \paragraph{General setting for binary graphs.} \refer{BJR07}: %\pause
  \begin{itemize}
   \item   \emphase{A latent (unobserved) variable $Z_i$} is associated with each node:
  $$
  \{Z_i\} \text{ iid } \sim \pi 
  $$
  \item 
  Edges \emphase{$Y_{ij} = \Ibb\{i \sim j\}$ are independent conditionally} to the $Z_i$'s:
  $$
  \{Y_{ij}\} \text{ independent } | \{Z_i\}: \Pr\{Y_{ij} = 1\} = \gamma(Z_i, Z_j)
  $$
  \end{itemize}

  \bigskip \pause
  \paragraph{We focus here on model approaches}, in contrast with, e.g.
  \begin{itemize}
  \item Graph clustering \refer{GiN02}, \refer{New04}; 
  \item Spectral clustering \refer{LBB08}.
  \end{itemize}

  }

%--------------------------------------------------------------------
\subsection*{State space models}
%--------------------------------------------------------------------
\frame{\frametitle{Latent space models}

  \vspace{-.5cm}
  \begin{tabular}{cc}
  \vspace{-.3\textheigth}
    \begin{tabular}{p{.5\textwidth}}
    \hspace{-.05\textwidth}
      \onslide+<1->{
	\paragraph{State-space model: principle.}}
	 \begin{itemize}
	   \onslide+<2->{
        \item Consider $n$ nodes ($i = 1..n$); \\ ~ } 
        \onslide+<3->{
        \item $Z_i = $ unobserved position of node $i$, e.g.
          $$
          \{Z_i\} \text{ iid } \sim \Ncal(0 ,I)
          $$} 
        \onslide+<4->{
        \item Edge $\{Y_{ij}\}$ independent given $\{Z_i\}$, e.g.
          $$
          \Pr\{Y_{ij} = 1\} = \gamma(Z_i, Z_j)
          $$
          \gamma(z, z') = f(||z, z'||).}
      \end{itemize}
    \end{tabular}
    & 
    \hspace{-.1\textheigth}
    \begin{tabular}{p{.5\textwidth}}
      \vspace{1cm}
      \begin{overprint}
        \onslide<3>
        \hspace{-.1\textwidth}
        \includegraphics[width=.5\textwidth]{\fignet/FigCLADAG-LPM-Y}    
        \onslide<4>
        \hspace{-.1\textwidth}
        \includegraphics[width=.5\textwidth]{\fignet/FigCLADAG-LPM-XY}    
        \onslide<5>
        \hspace{-.1\textwidth}
        \includegraphics[width=.5\textwidth]{\fignet/FigCLADAG-LPM-X1}    
        \onslide<6>
        \hspace{-.1\textwidth}
        \includegraphics[width=.5\textwidth]{\fignet/FigCLADAG-LPM-X2}    
        \onslide<7>
        \hspace{-.1\textwidth}
%         \includegraphics[width=.4\textwidth]{\fignet/FigCLADAG-LPM-adjmat}    
        $
        Y = \left( {\footnotesize
		\begin{array}{cccccc}
		0 & 1 & 1 & 0 & 1 & \dots \\
		0 & 0 & 1 & 0 & 1 & \dots \\
		0 & 0 & 0 & 0 & 0 & \dots \\
		0 & 0 & 0 & 0 & 1 & \dots \\
		0 & 0 & 0 & 0 & 0 & \dots \\
		\vdots & \vdots & \vdots & \vdots & \vdots & \ddots  
		\end{array}
        } \right)
        $
      \end{overprint}
    \end{tabular}
  \end{tabular}
  }

%--------------------------------------------------------------------
\frame{\frametitle{A variety of state-space models}

  \bigskip%\pause
  \paragraph{Continuous.} Latent position models.
  \begin{itemize}
   \item \refer{HRH02}: 
   $$
   Z_i \in \Rbb^d, \qquad \text{logit}[\gamma(z, z')] = a - |z-z'|
   $$
   \item \refer{HRT07}:
   $$
   Z_i \sim \sum_k p_k \Ncal_d(\mu_k, \sigma^2_k I)
   $$
   \item \refer{LoS06}:
   $$
   Z_i \sim \Ucal_{[0, 1]}, \qquad \gamma(z, z'): [0, 1]^2 \rightarrow [0, 1] =: \text{graphon function}
   $$
   \item \refer{DPV10}:
   $$
   Z_i \in \Scal_K, \qquad \gamma(z, z') = \sum_{k, \ell} z_k z'_\ell \gamma_{k\ell}
   $$
  \end{itemize}
%   %\bigskip%\pause
%   \paragraph{Discrete.} Hidden class models. 
%   \begin{itemize}
%    \item \refer{NoS01}:
%    $$
%    Z_i \in \{1, \dots, K\}, \qquad \gamma(k, \ell) = \gamma_{k\ell}.   
%    $$
%   \end{itemize}
  }

%--------------------------------------------------------------------
\frame{\frametitle{Stochastic Block Model (SBM)}

  \begin{tabular}{cc}
    \hspace{-.5cm}
    \begin{tabular}{p{.5\textwidth}}
      \onslide+<1->{
	\paragraph{A mixture model for random graphs.}} \refer{NoS01}
      \onslide+<2->{
	\begin{itemize}
        \item Consider $n$ nodes ($i = 1..n$); \\ ~ } 
        \onslide+<3->{
        \item $Z_i = $ unobserved label of node $i$:
          $$
          \{Z_i\} \text{ iid } \sim \Mcal(1; \pi)
          $$
          $\pi = (\pi_1, ... \pi_K)$; \\ ~ } 
        \onslide+<4->{
        \item Edge $Y_{ij}$ depends on the labels:
          $\{Y_{ij}\}$ independent given $\{Z_i\}$,
          $$
          \Pr\{Y_{ij} = 1\} = \gamma(Z_i, Z_j)
          $$}
      \end{itemize}
    \end{tabular}
    & 
    \hspace{-.5cm}
    \begin{tabular}{p{.5\textwidth}}
      \vspace{1cm}
      \begin{overprint}
        \onslide<2>
        \includegraphics[width=.75\textwidth]{\fignet/FigSBM-Model-1}    
        \onslide<3>
        \includegraphics[width=.75\textwidth]{\fignet/FigSBM-Model-2}    
        \onslide<4>
        \includegraphics[width=.75\textwidth]{\fignet/FigSBM-Model-3}    
        \onslide<5>
        \includegraphics[width=.75\textwidth]{\fignet/FigSBM-Model-5}    
      \end{overprint}
    \end{tabular}
  \end{tabular}
  }

%--------------------------------------------------------------------
%--------------------------------------------------------------------
\section{Variational inference}
\frame{\frametitle{Variational inference}

  Joint work with J.-J. Daudin, S. Gazal, F. Picard
}
%--------------------------------------------------------------------

%--------------------------------------------------------------------
\subsection*{Incomplete data models}
%--------------------------------------------------------------------
%--------------------------------------------------------------------
\frame{\frametitle{Incomplete data models}

	\paragraph{Aim.} Based on the observed network $Y = (Y_{ij})$, we want to infer
	\begin{itemize}
	\item the parameters
	$$
	\theta = (\pi, \gamma)
	$$
	\item the hidden states 
	$$
	Z = (Z_i)
	$$
	\end{itemize}

	\bigskip \bigskip \pause
	State space models belong to the class of incomplete data models as
	\begin{itemize}
	\item the edges $(Y_{ij})$ are observed,
	\item the latent positions (or status) $(Z_i)$ are not.
	\end{itemize}
	\ra usual issue in unsupervised classification.
}

%--------------------------------------------------------------------
\frame{\frametitle{Frequentist maximum likelihood inference}

  \paragraph{Likelihood.} The (log-)likelihood
  $$
  \log P(\Ybf; \thetabf) = \log \sum_{\zbf} P(\Ybf, \zbf; \thetabf)
  $$
  can not be computed.

  \pause\bigskip\bigskip
  \paragraph{EM trick.} But it can be decomposed as
  $$
  \log P(\Ybf; \thetabf) = \log P(\Ybf, \Zbf; \thetabf) - \log
  P(\Zbf | \Ybf; \thetabf), 
  $$
  \pause the conditional expectation of which gives
  \begin{eqnarray*}
    \Esp[\log P(\Ybf;\thetabf)|\Ybf] & = & \Esp[\log P(\Ybf, \Zbf;
    \thetabf)|\Ybf] - \Esp[\log P(\Zbf | \Ybf; \thetabf)|\Ybf] \\ 
    \pause
    \log P(\Ybf; \thetabf) & = & \Esp[\log P(\Ybf, \Zbf;
    \thetabf)|\Ybf] + \Hcal[P(\Zbf | \Ybf; \thetabf)]
  \end{eqnarray*}
  where $\Hcal$ stands for the entropy.
  }

%--------------------------------------------------------------------
\frame{\frametitle{EM algorithm}

  Aims at maximizing the log-likelihood
  $$
  \log P(\Ybf; \thetabf)
  $$
  through the alternation of two steps \refer{DLR77}
  
  \bigskip \pause 
  \paragraph{M-step:} maximize $\Esp[\log P(\Ybf, \Zbf;
    \thetabf)|\Ybf]$ with respect to $\theta$ \\
    \ra generally similar to standard MLE. \\
  
  \bigskip \pause 
  \paragraph{E-step:} calculate $P(\Zbf|\Ybf)$ (at least, some moments) \\
  \pause \ra sometimes straightforward (independent mixture models: Bayes formula) \\
  \pause \ra sometimes tricky but doable (HMMs: forward-backward recursion) \\
  \pause \ra sometimes impossible (SBM: ...) 
    }
%--------------------------------------------------------------------
\frame{\frametitle{Conditional distribution of $Z$}

  \begin{tabular}{cc}
    \hspace{-.5cm}
    \begin{tabular}{p{.5\textwidth}}
      \onslide+<1->{
        \paragraph{EM works} 
        provided that we can calculate
        $$
        P(\Zbf | \Ybf; \thetabf)
        $$}
      \onslide+<5->{but we can not for latent space graph model. \\ ~\\ ~\\
      }
    \end{tabular}
    & 
    \hspace{-.5cm}
    \begin{tabular}{p{.5\textwidth}}
	 \begin{overprint}
        \onslide<2>
        \includegraphics[width=0.6\textwidth]{../FIGURES/FigSBM-Z}
%        \epsfig{file=../FIGURES/FigSBM-Z.eps, clip=, width=0.6\textwidth}
        \onslide<3>
        \includegraphics[width=0.6\textwidth]{../FIGURES/FigSBM-Z-X12}
%         \epsfig{file=../FIGURES/FigSBM-Z-X12.eps, clip=, width=0.6\textwidth}
        \onslide<4>
        \includegraphics[width=0.6\textwidth]{../FIGURES/FigSBM-Z-X12-Moral} 
%         \epsfig{file=../FIGURES/FigSBM-Z-X12-Moral.eps, clip=, width=0.6\textwidth} 
        \onslide<5>
        \includegraphics[width=0.6\textwidth]{../FIGURES/FigSBM-Z-X-Moral} 
%         \epsfig{file=../FIGURES/FigSBM-Z-X-Moral.eps, clip=, width=0.6\textwidth} 
        \onslide<6->
        \includegraphics[width=0.6\textwidth]{../FIGURES/FigSBM-ZcondX}
%         \epsfig{file=../FIGURES/FigSBM-ZcondX.eps, clip=, width=0.6\textwidth}
      \end{overprint}
    \end{tabular}
  \end{tabular}

  \onslide+<6->{
    \vspace{-1.5cm}
    \paragraph{Conditional distribution.} The dependency graph of
    $\Zbf$ given $\Ybf$ is a clique. \\
    \ra No factorization can be hoped (unlike for HMM). \\
    \ra $P(\Zbf | \Ybf; \thetabf)$ can not be computed
    (efficiently). \\
    \ra Variational techniques may help as they provide 
    $$
    Q(\Zbf) \simeq P(\Zbf | \Ybf).
    $$
  }
}

%--------------------------------------------------------------------
\subsection*{Variationnal inference}
%--------------------------------------------------------------------
%--------------------------------------------------------------------
\frame{\frametitle{Variational inference}

  \paragraph{Lower bound of the log-likelihood.} For any distribution
  $Q(\Zbf)$ \refer{Jaa00,WaJ08},
  \begin{eqnarray*}
    \log P(\Ybf) & \geq & \log P(\Ybf) - KL[Q(\Zbf),
    P(\Zbf|\Ybf)] \\ \pause
%    & = & \log P(\Ybf; \thetabf) - \int Q(\zbf) \log Q(\zbf) \dd \zbf
%    + \int
%    Q(\zbf) \log P(\zbf|\Ybf) \\
%    & = & \log P(\Ybf; \thetabf) - \int Q(\zbf) \log Q(\zbf) \dd \zbf
%    + \int
%    Q(\zbf) \log P(\Ybf, \zbf) - \int Q(\zbf) \log P(\Ybf) \dd \zbf \\ 
    & = & \int Q(\zbf) \log P(\Ybf, \zbf) \dd \zbf - \int Q(\zbf) \log
    Q(\zbf) \dd \zbf \\ \pause
    & = & \Esp_Q[\log P(\Ybf, \Zbf)] + \Hcal[Q(\Zbf)] 
  \end{eqnarray*}
  
  \bigskip\bigskip\pause
  \paragraph{Link with EM.} This is similar to
  $$
  \log P(\Ybf) = \Esp[\log P(\Ybf, \Zbf)|\Ybf] + \Hcal[P(\Zbf | \Ybf)]
  $$
  replacing $P(\Zbf|\Ybf)$ with $Q(\Zbf)$.
  }
  
%--------------------------------------------------------------------
\frame{\frametitle{Variational EM algorithm}

  \paragraph{Variational EM.} 
  \begin{itemize}
  \item M-step: compute 
    $$
    \widehat{\thetabf} = \arg\max_\thetabf \emphase{\Esp_{Q^*}}[\log P(\Ybf,
    \Zbf; \thetabf)].
    $$
  \item \pause E-step: replace the calculation of $P(\Zbf|\Ybf)$ with
    the search of
    $$
    Q^*(\Zbf) = \emphase{\arg\min_{Q \in \Qcal} KL}[Q(\Zbf), P(\Zbf|\Ybf)].
    $$ 
    \pause ~\\
    \ra Taking $\Qcal = \{\text{all possible distributions}\}$ gives $Q^*(\Zbf) = P(\Zbf|\Ybf)$ ... like EM does. \\
    ~\\
   \ra Variational approximations rely on the choice a set $\Qcal$ of 'good' and 'tractable' ditributions.
  \end{itemize}

  }


  
%-------------------------------------------------------------------- 
\frame{ \frametitle{Variational EM for SBM}

  \paragraph{Distribution class.} $\Qcal =$ set of \emphase{factorisable}
  distributions:
  $$
  \Qcal = \{Q: Q(\Zbf) = \prod_i Q_i(Z_i)\}, \qquad\qquad Q_i(Z_i) = \prod_k
  \tau_{ik}^{Z_{ik}}.
  $$
  \ra The approximate joint distribution is $Q(Z_i, Z_j) = Q_i(Z_i)
  Q_j(Z_j)$. 

  \bigskip\bigskip\bigskip\pause
  The optimal approximation within this class satisfies a
  \emphase{fix-point} relation \refer{DPR08}:
  $$
  \tau_{ik} \propto \pi_k \prod_{j \neq i} \prod_\ell
  f_{k\ell}(Y_{ij})^{\emphase{\tau_{j\ell}}}
  $$
  also known as  \emphase{mean-field approximation} in physics \refer{Par88}. 
  }

%-------------------------------------------------------------------- 
\frame{ \frametitle{Some extensions and properties.}

  \paragraph{Variational Bayes.} A Bayesian extension of variational EM (VBEM) can defined as
  $$
  Q^*(\theta, Z) = \arg\min_{Q \in \Qcal} KL[Q(\theta, Z), P(\theta, Z |\Ybf)].
  $$
  Explicit formulas exists for exponential family models with conjugate priors \refer{BeG03}.
  
  \bigskip \bigskip \pause
  \paragraph{Model selection.} An ICL-like criterion can be derived \refer{DPR08}
  $$
  ICL = \Esp[\log P(\Ybf, \Zbf)|\Ybf] - \frac12 \left\{\frac{K(K+1)}2 \log \frac{n(n-1)}2 - (K-1) \log n\right\}.
  $$
  
  \bigskip \pause
  \paragraph{Variational estimates.}
  \begin{itemize}
   \item No general statistical guaranty for variational estimates.
   \item SBM is a very specific case for which the variational approximation is asymptotically exact \refer{CDP12}.
  \end{itemize}

  }


%--------------------------------------------------------------------
\frame{ \frametitle{{\VBEM} Credibility intervals and convergence}

  \paragraph{Actual level as a function of $n$:}   $\pi_1$: $+$,
  $\gamma_{11}$: \textcolor{red}{$\triangle$}, $\gamma_{12}$:
  \textcolor{blue}{$\circ$}, $\gamma_{22}$: \textcolor{green}{$\bullet$}
  $$
  \includegraphics[width=1\textwidth]{../FIGURES/im-ICQ2-2-new} 
  $$

  \pause
  \emphase{Width of the posterior credibility intervals.}
  {$\pi_1$}, \textcolor{red}{$\gamma_{11}$},
  \textcolor{blue}{$\gamma_{12}$}, \textcolor{green}{$\gamma_{22}$}
  \\
  \includegraphics[width=1\textwidth]{../FIGURES/im-ICQ2-3} \\

 }

%--------------------------------------------------------------------
%--------------------------------------------------------------------
\section{SBM analysis of biological networks}
\frame{\frametitle{SBM analysis of biological networks}

  Joint work with J.-J. Daudin, V. Miele, F. Picard

}
%--------------------------------------------------------------------

%-------------------------------------------------------------------- 
\frame{ \frametitle{SBM analysis of {\sl E. coli} operon networks}

  \vspace{-0.5cm}
  \hspace{-0.5cm}
  \begin{tabular}{cc}         
    \begin{tabular}{p{0.45\textwidth}}
    \begin{overprint}
       \onslide+<1->{
	%\vspace{-1cm}
        \includegraphics[width=.45\textwidth]{\fignet/im_EcoliVEM_2} \\
          %~\\
          \refer{PMD09}
         }
    \end{tabular}
    &
    \begin{tabular}{p{0.45\textwidth}}
     \onslide+<2->{
      \vspace{-.3cm}
      \paragraph{Meta-graph representation.} \\
      %\vspace{-.5cm}
      \includegraphics[width=.35\textwidth]{\fignet/VEMmetagraphe}  \\
     }
     \onslide+<3->{
      \vspace{-.3cm}
      \paragraph{Parameter estimates.} $K = 5$     \\
      \includegraphics[width=.35\textwidth]{../FIGURES/im-pi1BVEM}\\        
      \includegraphics[width=.35\textwidth]{../FIGURES/im-pi2BVEM}\\
      \includegraphics[width=.35\textwidth]{../FIGURES/im-pi3BVEM}\\
      \includegraphics[width=.35\textwidth]{../FIGURES/im-pi4BVEM}\\
      \includegraphics[width=.35\textwidth]{../FIGURES/im-pi5BVEM}\\
      \hline 
      \includegraphics[width=.35\textwidth]{../FIGURES/im-alphaBVEM}\\
     }
    \end{tabular}
  \end{tabular}
  }

%--------------------------------------------------------------------
\frame{ \frametitle{Tree interaction (valued) network}
  \begin{tabular}{cc}
    \hspace{-.5cm}
    \begin{tabular}{p{.4\textwidth}}
      \paragraph{Data:} $n = 51$ tree species, \\
      $Y_{ij}=$ number of shared parasites. \refer{VPD08}.

      \onslide+<2->{
        \bigskip
        \paragraph{Model:}
        $$
        Y_{ij} \sim \Pcal(\lambda_{k\ell}),
        $$
        $\lambda_{k\ell} =$ mean number of shared parasites.
        
        \bigskip
        \paragraph{Results:} ICL selects $K=7$ groups}
      \onslide+<3->{
        that are \emphase{strongly related with phylums}. 
        }
      \end{tabular}
    & 
    \hspace{-.75cm}
    \begin{tabular}{c}
      \onslide+<2->{
        {\tiny
          \begin{tabular}{c|ccccccc}
            $\widehat{\lambda}_{k\ell}$ & T1 & T2 & T3 & T4 & T5 & T6 &
            T7 \\ 
            \hline
            T1 & 14.46 & 4.19 & 5.99 & 7.67 & 2.44 & 0.13 & 1.43 \\
            T2 &  & 14.13 & 0.68 & 2.79 & 4.84 & 0.53 & 1.54 \\
            T3 &  &  & 3.19 & 4.10 & 0.66 & 0.02 & 0.69 \\
            T4 &  &  &  & 7.42 & 2.57 & 0.04 & 1.05 \\
            T5 &  &  &  &  & 3.64 & 0.23 & 0.83 \\
            T6 &  &  &  &  &  & 0.04 & 0.06 \\
            T7 &  &  &  &  &  &  & 0.27 \\
            \hline \hline
            $\widehat{\pi}_k$ & 7.8 & 7.8 & 13.7 & 13.7 & 15.7 & 19.6 &
            21.6  
          \end{tabular}
          }\\
        }
      \onslide+<3->{
        \includegraphics[width=.6\textheight, height=.6\textwidth, angle=270]{\fignet/MRV10_AoAS_Q7_group}
        }
    \end{tabular}
  \end{tabular}
  }

%--------------------------------------------------------------------
\frame{ \frametitle{Accounting for the taxonomic distance $d_{ij}$}
  \begin{tabular}{cc}
    \hspace{-.5cm}
    \begin{tabular}{p{.4\textwidth}}
      \paragraph{Model:}
      $$
      Y_{ij} \sim \Pcal[\lambda_{k\ell} \; \emphase{\exp(\beta d_{ij})}].
      $$

      \bigskip \pause
      \paragraph{Results:} $\widehat{\beta} = -0.317$. \\
      \ra for $\overline{d} = 3.82$, 
      $$
      e^{\widehat{\beta}\overline{d}} = .298
      $$
      \ra The mean number of shared parasites \emphase{decreases as
        the distance increases}.
      %\pause
    \end{tabular}
    & 
    %\hspace{-.75cm}
    \begin{tabular}{c}
      {\tiny
        \begin{tabular}{c|cccc}
          $\widehat{\lambda}_{k\ell}$ & T'1 & T'2 & T'3 & T'4 \\ 
          \hline
          T'1 & 0.75 & 2.46 & 0.40 & 3.77 \\
          T'2 &  & 4.30 & 0.52 & 8.77 \\ 
          T'3 &  &  & 0.080 & 1.05 \\ 
          T'4 &  &  &  & 14.22 \\
          \hline \hline
          $\widehat{\pi}_k$ & 17.7 & 21.5 & 23.5 & 37.3 \\
          \hline \hline
          $\widehat{\beta}$ & \multicolumn{4}{c}{-0.317}
        \end{tabular}
        } \\ 
      \pause
      \includegraphics[width=.5\textheight, height=.5\textwidth, angle=270]{\fignet/MRV10_AoAS_Q4_group}
    \end{tabular}
  \end{tabular}
  
%   \ra Groups are no longer associated with the phylogenetic
%   structure. \\
%   \ra Mixture $=$ \emphase{residual heterogeneity} of the regression.
  }

%--------------------------------------------------------------------
%--------------------------------------------------------------------
\section{Towards $W$-graphs}
\frame{\frametitle{Towards $W$-graphs}

  Ongoing work with P. Latouche.
}
%--------------------------------------------------------------------

%--------------------------------------------------------------------
\frame{ \frametitle{$W$-graph model}

  \begin{tabular}{cc}
    \hspace{-.5cm}
    \begin{tabular}{p{.5\textwidth}}
	 \paragraph{\refer{LoS06}.} ~\\
	 Latent variables:
	 $$
	 (Z_i) \text{ iid } \sim \Ucal_{[0, 1]},
	 $$
	 Graphon function $\gamma$:
	 $$
	 \gamma(z, z'): [0, 1]^2 \rightarrow [0, 1]
	 $$    
	 Edges:
	 $$
	 \Pr\{Y_{ij} = 1\} = \gamma(Z_i, Z_j)
	 $$    
	 \end{tabular}
    & 
    \hspace{-.1\textwidth}
    \begin{tabular}{p{.5\textwidth}}
	 Graphon function $\gamma(z, z')$ \\
      \includegraphics[width=.6\textwidth]{../FIGURES/FigCLADAG-W-graphon} \\
    \end{tabular}
  \end{tabular}

 }


%--------------------------------------------------------------------
\frame{ \frametitle{SBM as a $W$-graph model}

  \begin{tabular}{cc}
    \hspace{-.5cm}
    \begin{tabular}{p{.5\textwidth}}
	 Latent variables:
	 $$
	 (Z_i) \text{ iid } \sim \Mcal(1, \pi)
	 $$
	 Blockwise constant graphon:
	 $$
	 \gamma(z, z') = \gamma_{k\ell}
	 $$    
	 Edges:
	 $$
	 \Pr\{Y_{ij} = 1\} = \gamma(Z_i, Z_j)
	 $$    
	 \end{tabular}
    & 
    \hspace{-.1\textwidth}
    \begin{tabular}{p{.5\textwidth}}
	 Graphon function $\gamma^{SBM}_K(z, z')$ \\
      \includegraphics[width=.6\textwidth]{../FIGURES/FigCLADAG-SBM-graphon} \\
    \end{tabular}
  \end{tabular}

 }

%--------------------------------------------------------------------
\subsection*{Variational Bayes inference}
%--------------------------------------------------------------------
\frame{ \frametitle{Variational Bayes estimation of $\gamma(z, z')$}

  \paragraph{General idea.} Estimate the true $\gamma$ with a blockwise constant function $\gamma_K^{SBM}$ with $K$ classes.
  
  \bigskip \pause
  \paragraph{Method.} For $K = 1 .. K_{\max}$, fit an SBM model via VBEM and compute
  $$
  \widehat{\gamma}_K^{SBM}(z, z') = \Esp_Q[\gamma_{C(z), C(z')}].
  $$
  \pause Then
  \begin{itemize}
   \item either take $\widehat{\gamma} = \widehat{\gamma}_{\widehat{K}}^{SBM}$ where $\widehat{K}$ is chosen via ICL
   \item \pause or perform Bayesian model averaging (BMA) as
   $$
   \widehat{\gamma}(z, z') = \sum_K w_K \widehat{\gamma}_K^{SBM}(z, z')
   $$
   where $w_K$ is the variational weights arising from variational Bayes inference \refer{VMR12}.
  \end{itemize}

}

%--------------------------------------------------------------------
\frame{ \frametitle{French political blogosphere.}

  \paragraph{Website network.} French political blogs: 196 nodes, 1432 edges.
  $$
  \includegraphics[width=.65\textwidth]{../FIGURES/Blogosphere-raw}
  $$
}

%--------------------------------------------------------------------
\frame{ \frametitle{French political blogosphere.}

  \paragraph{Infered graphon.} $\widehat{W}(u, v) = \Esp(\gamma(u, v) | Y)$
  $$
  \includegraphics[width=.65\textwidth]{../FIGURES/Blogosphere-graphon}
  $$
  Motif probability can be estimated as well as $\widehat{\mu}(m) = \Esp(\mu(m) | Y)$.
}

%--------------------------------------------------------------------
\frame{\frametitle{Conclusion}

  \begin{itemize}
  \item Real networks are heterogeneous. \\ \pause ~
  \item State space models (including SBM) allow to capture such an heterogeneity ... \\
  but raise serious inference problem when dealing with graphs. \\ \pause ~
  \item Variational approximations help to deal with complex (conditional) dependency structures. \\ \pause ~
  \item SBM is a special (rare?) case for which guaranties exist as for the performances of the variational approximation.
  \end{itemize}
  }

%--------------------------------------------------------------------
{\tiny
  \bibliography{/home/robin/Biblio/ARC,/home/robin/Biblio/AST}%,/home/robin/Biblio/SSB}
  \bibliographystyle{/home/robin/LATEX/astats}
  %\bibliographystyle{plaine}
  }

%-------------------------------------------------------------------- 
\appendix
%-------------------------------------------------------------------- 
\frame{ \frametitle{SBM for a binary social network}

 \vspace{-.02\textheight}
 \includegraphics[width=.9\textwidth, height=.5\textheight]{\fignet/Karate-Graph}

%   \vspace{-.5cm}
  \begin{tabular}{ll}
    \begin{tabular}{p{.4\textwidth}}
    \paragraph{Zachary data.} Social binary network of friendship
    within a sport club. \\ 
    \\ 
%     \paragraph{Results.} 
%     The split is recovered and the role of few leaders is
%     underlined. 
    \end{tabular}
    & 
    \begin{tabular}{p{.5\textwidth}}
%     $
%     (Y_{ij}|Z_i=q, Z_j=\ell) \sim \Bcal(\gamma_{q\ell})
%     $ \\ ~\\
    {\small
    \begin{tabular}{c|rrrr}
    (\%) & \multicolumn{4}{c}{$\widehat{\gamma}_{k\ell}$} \\
    $k / \ell$ &  {1} & 2 & 3 &  4 \\
    \hline
    {1} &  {100} &   {53} &  {16} & {16} \\  
    {2} & - &  {12} & {0} & {7}  \\  
    3 & - & - & 8 & 73 \\
    4 & - & - & - & 100\\
    \hline
    $\widehat{\pi}_{\ell}$        & 9 &  38       & 47    & 6     \\
	 \end{tabular}}
    \end{tabular}
  \end{tabular}

}

%--------------------------------------------------------------------
\frame{\frametitle{Küllback-Leibler divergence}

  \paragraph{Definition.}
  \begin{eqnarray*}
    KL[Q(\cdot), P(\cdot)] & = & \int Q(\zbf) \log
    \frac{Q(\zbf)}{P(\zbf)} \dd \zbf \\
    & = & \int Q(\zbf) \log Q(\zbf) \dd \zbf - \int Q(\zbf) \log
    P(\zbf) \dd \zbf  
  \end{eqnarray*}

  \bigskip\bigskip%\pause
  \paragraph{Some properties.}
  \begin{itemize}
  \item Always positive.
  \item Null iff $P = Q$.
  \item Contrast consistent with maximum-likelihood inference.
  \item Not a distance, only a 'divergence'.
  \end{itemize}
  }

%-------------------------------------------------------------------- 
\frame{ \frametitle{Concentration of the degree distribution} 

  \begin{overprint}
   \onslide<1>
   \paragraph{$n = 100$.}
  $$
  \includegraphics[width=.5\textwidth, angle=270]{\fignet/ConcentrBinom-n100}
  $$
   \onslide<2>
   \paragraph{$n = 1000$.}
  $$
  \includegraphics[width=.5\textwidth, angle=270]{\fignet/ConcentrBinom-n1000}
  $$
   \onslide<3>
   \paragraph{$n = 10000$.}
  $$
  \includegraphics[width=.5\textwidth, angle=270]{\fignet/ConcentrBinom-n10000}
  $$
  \end{overprint}
  }
  


%--------------------------------------------------------------------
%--------------------------------------------------------------------
\end{document}
%--------------------------------------------------------------------
%--------------------------------------------------------------------

  \begin{tabular}{cc}
    \hspace{-.5cm}
    \begin{tabular}{p{.5\textwidth}}
    \end{tabular}
    & 
    \hspace{-.5cm}
    \begin{tabular}{p{.5\textwidth}}
    \end{tabular}
  \end{tabular}

