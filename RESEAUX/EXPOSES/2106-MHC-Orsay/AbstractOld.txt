Variational inference for latent variable models, and beyond

S. Robin

Variational inference has become a popular approach for the inference of complex latent variable models, as an alternative to the expectation-maximization (EM) algorithm. The critical step of EM-based inference is most often the evaluation of some moments of the conditional distribution of the latent variables given the observed ones. Variational inference resorts to an approximation of this conditional distribution, via the minimization of a KÃ¼llback-Leibler divergence.

Although they provide efficient algorithms, both in terms of computation time and empirical accuracy, variational approximations lack of statistical guaranty as for the estimates they provide. Such guaranty can be obtained in some specific cases, but at the price of a carefull and problem-specific analysis.

We will discuss how variational approximations can be used as a first step to achieve statistically grounded inference using either Monte-Carlo or composite likelihood approaches. In such combinations, variational approaches dramatically reduce the copmputational burden. We will illustrate the use of such combined approaches on latent variable models dedicated to the analysis of species abundance data and ecological networks.
