Stochastic blockmodels: beyond variational inference

S. Robin: joint works with S. Donnet and C. Matias

In the paste decades, the stochastic blockmodel has become a popular tool for the statistical analysis of networks. In its simple version, the model assumes that each node belongs to unobserved class and that the value of each edge depends on the respective node memberships. The presence of latent variables (the node memberships) and the specific structure of the data (a network), hamper standard frequentist or Bayesian statistical inference. Many approach rely on variational approximations, which result in efficient inference algorithms, but with few statistical guaranties.

We will introduce two attempts to build upon variational inference to achieve regular statistical inference with usual guaranties. We will first show how an approximate posterior distribution can be derived from a variational approximation and present a sequential Monte Carlo algorithm heading to the true posterior. We will then introduce a composite likelihood approach providing consistent and asymptotically normal estimators. 
