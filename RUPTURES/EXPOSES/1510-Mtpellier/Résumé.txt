Détection d'altérations récurrentes : quand le modèle statistique doit s'adapter à la dimension des données

<<
Les technologies génomiques modernes permettent de détecter des altérations génomiques (perte ou gain de régions chromosomiques) existantes chez un patients. On s'intéresse alors naturellement à déterminer quelles sont les altérations qui sont observées plus fréquemment parmi une cohorte de patients atteints d'une même maladie. De telles altérations sont dites "récurrentes".

Sous des hypothèses simples mais raisonnables, la significativité de telles régions peut être reformulée en termes d'excursions d'un processus markovien. Cependant, le calcul de la probabilité critique associées pose des problème combinatoires dont la complexité croît avec le nombre de patients $n$ et avec les nombre de locus $p$. Dans la dernière décennie, les avancées de la biologie moléculaire ont fait rapidement croître ces deux nombres.

Trois approches seront présentées, chacune adaptée à un ordre de grandeur, c'est à dire à une période d'un passé récent. Chaque approche repose sur des outils probabilistes différents. Ainsi l'analyse de puces CGH ($n$ et $p$ petits) peut être entreprise au moyen d'une chaîne de Markov "induite" (embedded Markov chain). Les processus de Markov à temps continu (de type naissances et morts) s'adaptent bien aux cas de données SNP ($n$ petit, $p$ grand). Pour ce qui est du séquençage massif (NGS : $n$ et $p$ grand), on a recourt à une processus limite de type Ornstein-Uhlenbeck.
>>
